1. 학습 날짜 // 

    2021-02-04(목)
 
2. 학습시간 // 

    09:00 ~ 18:00 (자가)
    
3. 학습 범위 및 주제 // 
    
    파이썬, 머신러닝
    
4. 동료 학습 방법 (온라인 또는 오프라인으로 동료 학습이 이뤄진 경우, 어떤 식으로 이뤄졌는지 기술) // 오프라인으로 만난경우 각각 슬랙 아이디 // 온라인(슬랙, 스카이프, 카카오톡)으로 피드백을 받는 경우 피드백해준 자 ID // 

    온라인을 통해 동료학습 하였다.  피드백해준 자 :gicho, jeonkim, sanhan, jungtlee, youcho, sanglee

5. 학습 목표 //

    머신러닝을 활용하여 얼굴인식 프로그램을 만든다.
    
6. 과제 제출 repository 주소 // 
    
    
    
7. 상세 학습 내용 (운영진 판단하에 학습 내용이 부진할 경우 재 제출 요구 예정) 필수사항 이외에 자유롭게 작성 가능 실제 코딩에 사용한 시간 (필수) 학습에 참고한 사이트 (홈페이지, 블로그, 동영상, 자료)와 간단한 내용(권고) 오늘 발견한 문제(버그, 몰랐던 것,...)와 해결 방안(필수) 다른 교육생들과의 협업, 토론 내용(권고) //
    
    09:00 ~ 18:00 동안 코드를 작성하였다.
    
        IMG_SIZE = 64
        first = True
        for ind in range(1, 100, 1) :
          path = files_path + str('%03d' %ind) + '/*.*'

          files = glob.glob(path)

          if 1<=ind<20: ind =0
          elif 20<=ind<50: ind=1
          else: ind=2

          tmpx = np.array([(cv2.resize(cv2.cvtColor(cv2.imread(x, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB), (IMG_SIZE,IMG_SIZE))) for x in files])
          tmpy = np.array([ind] * len(files)) #연령대별로 label 설정

          if len(files)==0: continue
          if first == True:
            data = tmpx.copy()
            labels = tmpy.copy()
            first = False
          else :
            data = np.concatenate((data, tmpx))
            labels = np.concatenate((labels, tmpy))

        start = 0
        end = cnt.values[0]
        num = 2300 # 각 클래스당 뽑을 데이터 수 (최소 개수를 가진 3클래스에 맞춤)

        for idx in range(0, 3, 1):
          if idx == 0:
            xdata = np.array(random.sample(list(data[start:end]), num))
            ydata = np.array([idx]*num)

            xtrain, xtest, ytrain, ytest = train_test_split(xdata, ydata, test_size=0.2, stratify=ydata, random_state=123)
            train_data = xtrain.copy()
            train_labels = ytrain.copy()
            test_data = xtest.copy()
            test_labels = ytest.copy()

            start = end
            end += cnt.values[idx+1]

          else:
            xdata = random.sample(list(data[start:end]), num)
            ydata = np.array([idx]*num)

            xtrain, xtest, ytrain, ytest = train_test_split(xdata, ydata, test_size=0.2, stratify=ydata, random_state=123)
            train_data = np.concatenate((train_data, xtrain))
            train_labels = np.concatenate((train_labels, ytrain))
            test_data = np.concatenate((test_data, xtest))
            test_labels = np.concatenate((test_labels, ytest))

            if idx == 2: continue
            start = end
            end += cnt.values[idx+1]

8. 학습 내용에 대한 개인적인 총평 (최소 5줄 이상) //

    정확도에 대한 근본적인 고민을 하던 중 연속적으로 변화하는 얼굴을 일정한 구간으로 잘라서 분류한다는 것이 쉽지 않다는 것을 깨달았다. 또한 0부터 70세 이상까지 10단위로 8개의 라벨로 분류하기 때문에 이것을 정확하게 구별하는 것이 어렵다는 것을 알았다. 따라서 프로그램의 목표를 20세 이하 20-50 50세 이상 총 3가지 계층으로 구별하는 것으로 다시 설정하고 라벨을 3개로 나누어서 모델을 구성하였다. 데이터셋 처리를 3에 맞게 다시 실행하고 모델을 학습시켜본 결과 정확도가 0.5에서 0.8 수준으로 향상된 것을 확인하였고 학습모델 검증 테스트에서도 높은 정답률을 보이는 것을 확인할 수 있었다. 
    
    데이터 라벨링을 다시 한 이후 정확도를 높이기 위해 기존에 했던 방법들을 다시 적용하면서 가장 최선의 모델을 찾기 위해 노력하였다. conv3 layer에 data augmentaion을 적용한 모델과 googlenet을 적용한 모델이 정확도가 높게 나왔고 둘중 가벼운 모델인 conv3 모델을 최종적으로 선정하였다.
    
    데이터셋과 라벨링의 중요성에 대해 깨달았다.
    
9. 다음 학습 계획 (최소 5줄 이상) // 
    
    자료구조, 파이썬에 대해 학습한다.
    
    libasm에 대해 공부하고 평가를 받는다.
    
    c++언어를 복습하며 심화학습한다.