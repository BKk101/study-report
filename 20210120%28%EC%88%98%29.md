1. 학습 날짜 // 

    2021-01-20(수)
 
2. 학습시간 // 

    09:00 ~ 18:00 (자가)
    
3. 학습 범위 및 주제 // 
    
    파이썬, 머신러닝
    
4. 동료 학습 방법 (온라인 또는 오프라인으로 동료 학습이 이뤄진 경우, 어떤 식으로 이뤄졌는지 기술) // 오프라인으로 만난경우 각각 슬랙 아이디 // 온라인(슬랙, 스카이프, 카카오톡)으로 피드백을 받는 경우 피드백해준 자 ID // 

    온라인을 통해 동료학습 하였다.  피드백해준 자 :gicho, jeonkim, sanhan, jungtlee, youcho, sanglee

5. 학습 목표 //

    머신러닝의 기본 개념을 학습한다.
    
6. 과제 제출 repository 주소 // 
    
    
    
7. 상세 학습 내용 (운영진 판단하에 학습 내용이 부진할 경우 재 제출 요구 예정) 필수사항 이외에 자유롭게 작성 가능 실제 코딩에 사용한 시간 (필수) 학습에 참고한 사이트 (홈페이지, 블로그, 동영상, 자료)와 간단한 내용(권고) 오늘 발견한 문제(버그, 몰랐던 것,...)와 해결 방안(필수) 다른 교육생들과의 협업, 토론 내용(권고) //
    
    09:00 ~ 18:00 동안 코드를 작성하였다.
        
        # Logistic regression : Binary Classification data
        x_input = tf.constant([[1, 1], [2, 1], [1, 2], [0.5, 4], [4, 1], [2.5, 2.3]], dtype= tf.float32)
        labels = tf.constant([[0], [0], [0], [1], [1], [1]], dtype= tf.float32)

        W = tf.Variable(tf.random.normal((2, 1)), dtype=tf.float32)
        B = tf.Variable(tf.random.normal((1,)), dtype=tf.float32)

        def Hypothesis(x):
          return tf.sigmoid(tf.matmul(x ,W) + B)

        def Cost():
          return -tf.reduce_mean(labels * tf.math.log(Hypothesis(x_input)) + (1 - labels) * tf.math.log(1 - Hypothesis(x_input)))

        epochs = 50000
        learning_rate = 0.01
        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)

        training_idx = np.arange(0, epochs+1, 1)
        cost_graph = np.zeros(epochs+1)
        check = np.array([0, epochs*0.01, epochs*0.08, epochs*0.2, epochs*0.4, epochs])

        W_trained = []
        b_trained = []
        check_idx = 0

        # 학습 (Training)
        for cnt in range(0, epochs+1):
          cost_graph[cnt] = Cost()
          if cnt % (epochs/20) == 0:
            print("[{:>5}] cost = {:>10.4}, W = [[{:>7.4}] [{:>7.4}]], B = [[{:>7.4}]]".format(cnt, cost_graph[cnt], W[0][0], W[1][0], B[0]))  
          if check[check_idx] == cnt:
            W_trained.append(W.numpy())
            b_trained.append(B.numpy())
            check_idx += 1

          optimizer.minimize(Cost,[W, B])
   
8. 학습 내용에 대한 개인적인 총평 (최소 5줄 이상) //
    
    선형회귀를 통해 모델을 설정하는 방법은 이를 통해서 어떤 input에 따른 결과를 예측하기 위해 사용된다. 어떤 값을 가지고 단계를 나누어 분류를 하는 작업에서도 머신러닝을 활용할 수 있는데 이때 선형회귀와 같은 Mean sqaured error 방법을 통해서는 cost를 평가할 수 없어 제대로된 답을 구할 수 없다. 따라서 분류를 위해서는 새로운 방법이 필요하고 cost의 값을 구하기 위해 Cross Entropy Error 방식을 이용한다. 또한 hypothesis에서 sigmoid라는 함수를 이용하여 어떤 값을 0~1 사이로 변환하여 분류에 용이하게 만든다.

    
9. 다음 학습 계획 (최소 5줄 이상) // 
    
    자료구조, 파이썬에 대해 학습한다.
    
    libasm에 대해 공부하고 평가를 받는다.
    
    c++언어를 복습하며 심화학습한다.